{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "导入了d2l包中的绘图类，方便直观地绘制损失的变换"
      ],
      "metadata": {
        "id": "9OcQ6wXHVy2w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RWA03LCUcTZ"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "!pip install d2l==0.17.5.\n",
        "%matplotlib inline\n",
        "from d2l import torch as d2l\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import os\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4Y30DecUkeX"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "自定义图片加载方法，将图片转换到需要的尺寸（128 or 512）和格式（torch tensor）"
      ],
      "metadata": {
        "id": "PByT7Rc4Qzag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmDj1FVTUlx-"
      },
      "outputs": [],
      "source": [
        "imsize = 512 if torch.cuda.is_available() else 128  # 如果没有GPU，就使用较小的图像尺寸\n",
        "\n",
        "loader = transforms.Compose([\n",
        "    transforms.Resize(imsize),  # 修改图片尺寸\n",
        "    transforms.ToTensor()])  # 转成torch tensor格式\n",
        "\n",
        "\n",
        "def image_loader(image_name):\n",
        "    image = Image.open(image_name)\n",
        "    # 拟合网络输入尺寸所需的额外批维度\n",
        "    image = loader(image).unsqueeze(0)\n",
        "    return image.to(device, torch.float)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "从Drive云端硬盘读取素材图片"
      ],
      "metadata": {
        "id": "qMYtJ54PRNAX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8gMGbMaEgAz"
      },
      "outputs": [],
      "source": [
        "# 从云端硬盘读取输入\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDKC0DegEnA-"
      },
      "outputs": [],
      "source": [
        "# 内容图像和风格图像\n",
        "content_img = image_loader(\"xmlg.jpg\")\n",
        "style_img = image_loader(\"bjs.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "转换成PIL格式便于后续操作"
      ],
      "metadata": {
        "id": "JmLKhV4kRVIA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZmr-JbSUnd8"
      },
      "outputs": [],
      "source": [
        "plt.ion()\n",
        "\n",
        "def imshow(tensor, title=None):\n",
        "    image = tensor.cpu().clone()  # 在副本上操作\n",
        "    image = image.squeeze(0)      # 移除此前设置的额外维度\n",
        "    image = transforms.ToPILImage()(image)\n",
        "    plt.imshow(image)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.01) # 暂停一会等待绘图完成\n",
        "\n",
        "# plt.figure()\n",
        "imshow(content_img, title='Content Image')\n",
        "\n",
        "# plt.figure()\n",
        "imshow(style_img, title='Style Image')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "定义两个距离，一个用于内容Dc和一个用于样式 Ds。Dc测量两个图像之间的内容差异，同时Ds测量两个图像之间的样式差异。然后，获取第三个图像，即输入，并对其进行转换，以最小化其与内容图像的内容距离和与样式图像的样式距离。"
      ],
      "metadata": {
        "id": "lY7ftm-ASCLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "内容损失函数表示加权后单层内容与原输入间的距离，该函数采用特征图的图层在网络处理输入中X并返回加权内容和之间距离。内容图像的特征图。将此函数实现为torch模块，其构造函数作为输入。距||FXL−FCL||2是两组特征映射之间的均方误差，可以使用nn.MSELoss 计算。"
      ],
      "metadata": {
        "id": "95cFc0ZPSL1j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIzfSkvBfUiz"
      },
      "outputs": [],
      "source": [
        "class ContentLoss(nn.Module): # 内容损失\n",
        "\n",
        "    def __init__(self, target,):\n",
        "        super(ContentLoss, self).__init__()\n",
        "        self.loss = None\n",
        "        self.target = target.detach()\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.loss = func.mse_loss(input, self.target)\n",
        "        return input"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "样式丢失模块的实现方式与内容丢失模块类似。它将充当网络中的透明层，用于计算该层的样式损失。为了计算样式损失，需要计算gram矩阵GXL.格拉姆矩阵是将给定矩阵乘以其转置矩阵的结果。"
      ],
      "metadata": {
        "id": "PGblyZ1vSgWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "必须通过将每个元素除以矩阵中的元素总数来规范化格拉姆矩阵。这种规范化是为了抵消以下影响： F^XL具有很大的矩阵维度N，在 Gram 矩阵中产生较大的值。这些较大的值将导致第一层（在池化层之前）在梯度下降期间产生更大的影响，而样式特征往往位于网络的更深层。"
      ],
      "metadata": {
        "id": "PtAC2t3mSllD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--wn7VkTfXTF"
      },
      "outputs": [],
      "source": [
        "def gram_matrix(input): # 格拉姆矩阵\n",
        "    channels, n = input.shape[1], input.numel() // input.shape[1]\n",
        "    input = input.reshape((channels, n))\n",
        "    return torch.matmul(input, input.T) / (channels * n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtsO5qrkfY91"
      },
      "outputs": [],
      "source": [
        "class StyleLoss(nn.Module): #风格损失\n",
        "\n",
        "    def __init__(self, target_feature):\n",
        "        super(StyleLoss, self).__init__()\n",
        "        self.loss = None\n",
        "        self.target = gram_matrix(target_feature).detach()\n",
        "\n",
        "    def forward(self, input):\n",
        "        g = gram_matrix(input)\n",
        "        self.loss = func.mse_loss(g, self.target)\n",
        "        return input"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch的VGG实现是一个模块，分为两个Sequential 子模块：features （卷积层和池化层）和classifier （完全连接层）。这里使用features 模块，因为需要各个卷积层的输出来测量内容和样式损失。某些层在训练期间的行为与评估时的行为不同，因此必须使用.eval()将网络设置为评估模式。VGG网络在图像上进行训练，每个通道归一化为meanst=[0.485， 0.456， 0.406]和std=[0.229， 0.224， 0.225]。在将图像输入到网络之前，将使用它们对其进行规范化。"
      ],
      "metadata": {
        "id": "GM4q06D5Sou1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEakdqNyfcee"
      },
      "outputs": [],
      "source": [
        "cnn = models.vgg19(pretrained=True).features.to(device).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXmOlbG_feAY"
      },
      "outputs": [],
      "source": [
        "cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
        "cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
        "\n",
        "class Normalization(nn.Module): # 标准化以便在网络上操作\n",
        "    def __init__(self, mean, std):\n",
        "        super(Normalization, self).__init__()\n",
        "        # 使其变成 [C x 1 x 1] 以便于直接和 [B x C x H x W] 的图像张量操作\n",
        "        # B(batch size)批处理大小. C(channels) 通道数. H(height) 高. W(width) 宽.\n",
        "        self.mean = torch.tensor(mean).view(-1, 1, 1)\n",
        "        self.std = torch.tensor(std).view(-1, 1, 1)\n",
        "\n",
        "    def forward(self, img):\n",
        "        # 标准化图像张量\n",
        "        return (img - self.mean) / self.std"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用L-BFGS算法来运行梯度下降。与训练网络不同，这里希望训练输入图像，以尽量减少内容/样式损失。将创建一个PyTorch L-BFGS优化器optim.LBFGS，并将图像作为要优化的张量传递给它。"
      ],
      "metadata": {
        "id": "pPn2__bIUMHV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v62AGhVZffMf"
      },
      "outputs": [],
      "source": [
        "# 计算 内容/风格 损失 :\n",
        "content_layers_default = ['conv_4']\n",
        "style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
        "\n",
        "def get_style_model_and_losses(cnn, normalization_mean, normalization_std,\n",
        "                               style_img, content_img,\n",
        "                               content_layers=content_layers_default,\n",
        "                               style_layers=style_layers_default):\n",
        "    # 标准化模块\n",
        "    normalization = Normalization(normalization_mean, normalization_std).to(device)\n",
        "\n",
        "    # 损失\n",
        "    content_losses = []\n",
        "    style_losses = []\n",
        "\n",
        "    # 假定cnn是nn.Sequential\n",
        "    model = nn.Sequential(normalization)\n",
        "\n",
        "    i = 0  # 每次遇到卷积层时+1\n",
        "    for layer in cnn.children():\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            i += 1\n",
        "            name = 'conv_{}'.format(i)\n",
        "        elif isinstance(layer, nn.ReLU):\n",
        "            name = 'relu_{}'.format(i)\n",
        "            # 原地操作不适用于内容损失函数和风格损失函数，所以这里采用异地操作\n",
        "            layer = nn.ReLU(inplace=False)\n",
        "        elif isinstance(layer, nn.MaxPool2d):\n",
        "            name = 'pool_{}'.format(i)\n",
        "        elif isinstance(layer, nn.BatchNorm2d):\n",
        "            name = 'bn_{}'.format(i)\n",
        "        else:\n",
        "            raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
        "\n",
        "        model.add_module(name, layer)\n",
        "\n",
        "        if name in content_layers:\n",
        "            # add content loss:\n",
        "            target = model(content_img).detach()\n",
        "            content_loss = ContentLoss(target)\n",
        "            model.add_module(\"content_loss_{}\".format(i), content_loss)\n",
        "            content_losses.append(content_loss)\n",
        "\n",
        "        if name in style_layers:\n",
        "            # add style loss:\n",
        "            target_feature = model(style_img).detach()\n",
        "            style_loss = StyleLoss(target_feature)\n",
        "            model.add_module(\"style_loss_{}\".format(i), style_loss)\n",
        "            style_losses.append(style_loss)\n",
        "\n",
        "    # 最后一次计算完内容损失和风格损失后裁剪图层\n",
        "    for i in range(len(model) - 1, -1, -1):\n",
        "        if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
        "            break\n",
        "\n",
        "    model = model[:(i + 1)]\n",
        "\n",
        "    return model, style_losses, content_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyrexrEdfgVo"
      },
      "outputs": [],
      "source": [
        "input_img = content_img.clone()\n",
        "\n",
        "plt.figure()\n",
        "imshow(input_img, title='Input Image')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用L-BFGS算法来运行梯度下降。与训练网络不同，这里希望训练输入图像，以尽量减少内容/样式损失。将创建一个PyTorch L-BFGS优化器optim.LBFGS，并将图像作为要优化的张量传递给它。"
      ],
      "metadata": {
        "id": "77qIUnzJUfVL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umIt8Mvkfi5p"
      },
      "outputs": [],
      "source": [
        "def run_style_transfer(cnn, normalization_mean, normalization_std,\n",
        "                       content_img, style_img, input_img, num_steps=300,\n",
        "                       style_weight=10000, content_weight=1):\n",
        "\n",
        "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
        "                            xlim=[50, num_steps],\n",
        "                            legend=['content', 'style','TV'],\n",
        "                            ncols=1, figsize=(7, 2.5))\n",
        "\n",
        "    \"\"\"开始运行风格迁移.\"\"\"\n",
        "    model, style_losses, content_losses = get_style_model_and_losses(cnn,\n",
        "        normalization_mean, normalization_std, style_img, content_img)\n",
        "\n",
        "    # 需要优化输入的拷贝而不是模型的参数，所以根据需要更新所有的梯度\n",
        "    input_img.requires_grad_(True)\n",
        "    model.requires_grad_(False)\n",
        "\n",
        "    optimizer = optim.LBFGS([input_img])\n",
        "\n",
        "    run = [0]\n",
        "    while run[0] <= num_steps:\n",
        "\n",
        "        def closure():\n",
        "            # 更正更新后的输入\n",
        "            with torch.no_grad():\n",
        "                input_img.clamp_(0, 1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            model(input_img)\n",
        "            style_score = 0\n",
        "            content_score = 0\n",
        "\n",
        "            for sl in style_losses:\n",
        "                style_score += sl.loss\n",
        "            for cl in content_losses:\n",
        "                content_score += cl.loss\n",
        "\n",
        "            style_score *= style_weight\n",
        "            content_score *= content_weight\n",
        "\n",
        "            loss = style_score + content_score\n",
        "            loss.backward()\n",
        "\n",
        "            run[0] += 1\n",
        "\n",
        "            if (run[0]+1) % 10 == 0 and run[0]>=49:\n",
        "                animator.add(run[0], [float(content_score.item()),\n",
        "                                     float(style_score.item()),float(loss.item())])\n",
        "\n",
        "            return style_score + content_score\n",
        "\n",
        "        optimizer.step(closure)\n",
        "\n",
        "    # 最后还需修正\n",
        "    with torch.no_grad():\n",
        "        input_img.clamp_(0, 1)\n",
        "\n",
        "    return input_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvxlSIn6fkHx"
      },
      "outputs": [],
      "source": [
        "output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std,\n",
        "                            content_img, style_img, input_img)\n",
        "plt.figure()\n",
        "imshow(output, title='Output Image')\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Work03.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}